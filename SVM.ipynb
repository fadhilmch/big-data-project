{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_raw = pd.read_csv('./data/cleaned_train.csv', sep=',')\n",
    "train_dataset_raw.columns = ['review', 'sentiment']\n",
    "\n",
    "test_dataset_raw = pd.read_csv('./data/cleaned_test.csv', sep=',')\n",
    "test_dataset_raw.columns = ['review', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_raw = pd.concat([dataset.loc[dataset['sentiment'] == 0].iloc[0:1000], dataset.loc[dataset['sentiment'] == 1].iloc[0:1000]])\n",
    "test_dataset_raw = pd.concat([dataset.loc[dataset['sentiment'] == 0].iloc[1001:1500], dataset.loc[dataset['sentiment'] == 1].iloc[1001:1500]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dived many times for the ball managed to save ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not the whole crew</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nope they did not have it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spring break in plain city it snowing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>could not bear to watch it and thought the ua ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  dived many times for the ball managed to save ...          0\n",
       "1                                 not the whole crew          0\n",
       "2                          nope they did not have it          0\n",
       "3              spring break in plain city it snowing          0\n",
       "4  could not bear to watch it and thought the ua ...          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finally\n"
     ]
    }
   ],
   "source": [
    "def reduce_lengthening(text):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)\n",
    "\n",
    "print (reduce_lengthening( \"finallllllly\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('big.txt').read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(data, norm_type, stop_words_list=None, spell_correction=False):\n",
    "    stop_words = ['in', 'of', 'the', 'at', 'a', 'an', 'is', 'are', 'am', 'was', 'were']\n",
    "    \n",
    "    if(stop_words_list=='corpus'):\n",
    "        data['review'] = [' '.join([word for word in x.split() if word not in set(stopwords.words('english'))]) \n",
    "                                   for x in data['review'].tolist()] # remove stop words\n",
    "    elif(stop_words_list=='manual'):\n",
    "        data['review'] = [' '.join([word for word in x.split() if word not in stop_words]) \n",
    "                               for x in data['review'].tolist()] # remove stop words\n",
    "    if spell_correction:\n",
    "        data['review'] = [' '.join([correction(reduce_lengthening(word)) for word in x.split()]) \n",
    "                               for x in data['review'].tolist()] #stem words   \n",
    "    if norm_type == 'stem':\n",
    "        normalizer = PorterStemmer()\n",
    "        data['review'] = [' '.join([normalizer.stem(word) for word in x.split()]) \n",
    "                               for x in data['review'].tolist()] #stem words\n",
    "    elif norm_type == 'lemma':\n",
    "        normalizer = WordNetLemmatizer()\n",
    "        data['review'] = [' '.join([normalizer.lemmatize(word) for word in x.split()]) \n",
    "                               for x in data['review'].tolist()] #lemmatize words\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_classifier_sampling(train, test, vectorizer, sampling_type, ngram_range = None, use_params = False):\n",
    "    if vectorizer == 'cv':\n",
    "        vctr = CountVectorizer()\n",
    "    elif vectorizer == 'ngram':\n",
    "        vctr = CountVectorizer(ngram_range=ngram_range)\n",
    "    elif vectorizer == 'tfidf':\n",
    "        vctr = TfidfVectorizer(ngram_range=ngram_range, max_df=0.7, min_df=2)\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    train_review = train['review']\n",
    "    test_review = test['review']\n",
    "    \n",
    "    train_review = vctr.fit_transform(train_review).toarray()\n",
    "    test_review = vctr.transform(test_review).toarray()\n",
    "    \n",
    "    train_review = sc.fit_transform(train_review)\n",
    "    test_review = sc.transform(test_review)\n",
    "    \n",
    "    train_label = train['sentiment']\n",
    "    test_label = test['sentiment']\n",
    "    \n",
    "    if sampling_type == 'over':\n",
    "        ros = RandomOverSampler(random_state=10)\n",
    "        ros_train_review, ros_train_label = ros.fit_sample(train_review, train_label)\n",
    "    elif sampling_type == 'under':\n",
    "        ros = RandomUnderSampler(random_state=10)\n",
    "        ros_train_review, ros_train_label = ros.fit_sample(train_review, train_label)        \n",
    "    elif sampling_type == 'smote':\n",
    "        ros = SMOTE(kind='svm')\n",
    "        ros_train_review, ros_train_label = ros.fit_sample(train_review, train_label)\n",
    "    else:\n",
    "        ros_train_review = train_review\n",
    "        ros_train_label = train_label\n",
    "        \n",
    "    if(use_params):\n",
    "        params = find_params(ros_train_review, ros_train_label)\n",
    "        print('Best params: %s' % (params))\n",
    "        svm_clf = SVC(C=params['C'], gamma=params['gamma'])\n",
    "    else:\n",
    "        svm_clf = SVC(C=0.001, gamma=3.727593720314938e-09)\n",
    "    svm_clf.fit(ros_train_review, ros_train_label)\n",
    "    \n",
    "    label_pred = svm_clf.predict(test_review)\n",
    "    \n",
    "    cm = confusion_matrix(test_label, label_pred)\n",
    "    \n",
    "    accuracy = accuracy_score(label_pred, test_label)\n",
    "    \n",
    "    return label_pred, cm, svm_clf, accuracy, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_params(x_train, y_train):\n",
    "    C_range = np.logspace(-3, 13, 17)\n",
    "    gamma_range = np.logspace(-13,3,17)\n",
    "    param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "    cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "    grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "    grid.fit(x_train, y_train)\n",
    "    \n",
    "    # Draw plot for gamma-C value result\n",
    "    score_dict = grid.grid_scores_\n",
    "\n",
    "    scores = [x[1] for x in score_dict]\n",
    "    scores = np.array(scores).reshape(len(C_range), len(gamma_range))\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.subplots_adjust(left=0.15, right=0.95, bottom=0.15, top=0.95)\n",
    "    plt.imshow(scores, interpolation='nearest', cmap=plt.cm.get_cmap(\"Spectral\"))\n",
    "    plt.xlabel('gamma')\n",
    "    plt.ylabel('C')\n",
    "    plt.colorbar()\n",
    "    plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "    plt.yticks(np.arange(len(C_range)), C_range)\n",
    "    plt.show()\n",
    "    \n",
    "    return grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset_raw.copy()\n",
    "test_dataset = test_dataset_raw.copy()\n",
    "\n",
    "train_dataset = data_preprocess(train_dataset, 'stem')\n",
    "test_dataset = data_preprocess(test_dataset, 'stem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred, cm, clf, accuracy, test_label = svm_classifier_sampling(train_dataset, test_dataset, 'tfidf', sampling_type = False, ngram_range = (1,2), use_params = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5721442885771543"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[472,  27],\n",
       "       [400,  99]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred_2, cm_2, clf_2, accuracy_2, test_label_2 = svm_classifier_sampling(train_dataset, test_dataset, 'tfidf', sampling_type = 'under', ngram_range = (1,2), use_params = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5711422845691383"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[472,  27],\n",
       "       [401,  98]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred_3, cm_3, clf_3, accuracy_3, test_label_3 = svm_classifier_sampling(train_dataset, test_dataset, 'tfidf', sampling_type = 'under', ngram_range = (1,2), use_params = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5721442885771543"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[472,  27],\n",
       "       [400,  99]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset_raw.copy()\n",
    "test_dataset = test_dataset_raw.copy()\n",
    "\n",
    "train_dataset = data_preprocess(train_dataset, 'stem', stop_words_list='manual')\n",
    "test_dataset = data_preprocess(test_dataset, 'stem', stop_words_list='manual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred_4, cm_4, clf_4, accuracy_4, test_label_4 = svm_classifier_sampling(train_dataset, test_dataset, 'tfidf', sampling_type = False, ngram_range = (1,2), use_params = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5621242484969939"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[466,  33],\n",
       "       [404,  95]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset_raw.copy()\n",
    "test_dataset = test_dataset_raw.copy()\n",
    "\n",
    "train_dataset = data_preprocess(train_dataset, 'stem', stop_words_list='corpus')\n",
    "test_dataset = data_preprocess(test_dataset, 'stem', stop_words_list='corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred_5, cm_5, clf_5, accuracy_5, test_label_5 = svm_classifier_sampling(train_dataset, test_dataset, 'tfidf', sampling_type = False, ngram_range = (1,2), use_params = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5390781563126252"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[463,  36],\n",
       "       [424,  75]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset_raw.copy()\n",
    "test_dataset = test_dataset_raw.copy()\n",
    "\n",
    "train_dataset = data_preprocess(train_dataset, 'stem', stop_words_list='manual', spell_correction=True)\n",
    "test_dataset = data_preprocess(test_dataset, 'stem', stop_words_list='manual', spell_correction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred_6, cm_6, clf_6, accuracy_6, test_label_6 = svm_classifier_sampling(train_dataset, test_dataset, 'tfidf', sampling_type = False, ngram_range = (1,2), use_params = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5791583166332666"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[461,  38],\n",
       "       [382, 117]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset_raw.copy()\n",
    "test_dataset = test_dataset_raw.copy()\n",
    "\n",
    "train_dataset = data_preprocess(train_dataset, 'stem', stop_words_list='manual', spell_correction=False)\n",
    "test_dataset = data_preprocess(test_dataset, 'stem', stop_words_list='manual', spell_correction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred_7, cm_7, clf_7, accuracy_7, test_label_7 = svm_classifier_sampling(train_dataset, test_dataset, 'tfidf', sampling_type = False, ngram_range = (1,3), use_params = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6703406813627254"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[316, 183],\n",
       "       [146, 353]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred_8, cm_8, clf_8, accuracy_8, test_label_8 = svm_classifier_sampling(train_dataset, test_dataset, 'tfidf', sampling_type = 'under', ngram_range = (1,3), use_params = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6703406813627254"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[316, 183],\n",
       "       [146, 353]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred_9, cm_9, clf_9, accuracy_9, test_label_9 = svm_classifier_sampling(train_dataset, test_dataset, 'tfidf', sampling_type = 'over', ngram_range = (1,3), use_params = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6703406813627254"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[316, 183],\n",
       "       [146, 353]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred_10, cm_10, clf_10, accuracy_10, test_label_10 = svm_classifier_sampling(train_dataset_raw, test_dataset_raw, 'tfidf', sampling_type = None, ngram_range = (1,3), use_params = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
